{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import wandb\n",
    "import random\n",
    "import intel_extension_for_pytorch as ipex\n",
    "import os.path\n",
    "import random\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch import save\n",
    "from math import log10\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.autograd import Variable\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_conv(in_channels, out_channels, kernel_size, bias):\n",
    "    return nn.Conv2d(\n",
    "        in_channels, out_channels, kernel_size, padding=(kernel_size // 2), bias=bias\n",
    "    )\n",
    "\n",
    "\n",
    "class UpConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UpConv, self).__init__()\n",
    "        self.body = nn.Sequential(\n",
    "            default_conv(3, 12, 3, True),\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.body(x)\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, n_feats):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        modules_body = [\n",
    "            default_conv(n_feats, n_feats, 3, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            default_conv(n_feats, n_feats, 3, bias=True)\n",
    "        ]\n",
    "        self.body = nn.Sequential(*modules_body)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.body(x)\n",
    "        res += x\n",
    "        return res\n",
    "\n",
    "\n",
    "class SingleScaleNet(nn.Module):\n",
    "    def __init__(self, n_feats, n_resblocks, is_skip, n_channels=3):\n",
    "        super(SingleScaleNet, self).__init__()\n",
    "        self.is_skip = is_skip\n",
    "\n",
    "        modules_head = [\n",
    "            default_conv(n_channels, n_feats, 5, bias=True),\n",
    "            nn.ReLU(inplace=True)]\n",
    "\n",
    "        modules_body = [\n",
    "            ResidualBlock(n_feats)\n",
    "            for _ in range(n_resblocks)\n",
    "        ]\n",
    "\n",
    "        modules_tail = [default_conv(n_feats, 3, 5, bias=True)]\n",
    "\n",
    "        self.head = nn.Sequential(*modules_head)\n",
    "        self.body = nn.Sequential(*modules_body)\n",
    "        self.tail = nn.Sequential(*modules_tail)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.head(x)\n",
    "\n",
    "        res = self.body(x)\n",
    "        if self.is_skip:\n",
    "            res += x\n",
    "\n",
    "        res = self.tail(res)\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "class MultiScaleNet(nn.Module):\n",
    "    def __init__(self, n_feats, n_resblocks, is_skip):\n",
    "        super(MultiScaleNet, self).__init__()\n",
    "\n",
    "        self.scale3_net = SingleScaleNet(n_feats, n_resblocks, is_skip, n_channels=3)\n",
    "        self.upconv3 = UpConv()\n",
    "\n",
    "        self.scale2_net = SingleScaleNet(n_feats, n_resblocks, is_skip, n_channels=6)\n",
    "        self.upconv2 = UpConv()\n",
    "\n",
    "        self.scale1_net = SingleScaleNet(n_feats, n_resblocks, is_skip, n_channels=6)\n",
    "\n",
    "    def forward(self, mulscale_input):\n",
    "        input_b1, input_b2, input_b3 = mulscale_input\n",
    "\n",
    "        output_l3 = self.scale3_net(input_b3)\n",
    "        output_l3_up = self.upconv3(output_l3)\n",
    "\n",
    "        output_l2 = self.scale2_net(torch.cat((input_b2, output_l3_up), 1))\n",
    "        output_l2_up = self.upconv2(output_l2)\n",
    "\n",
    "        output_l1 = self.scale2_net(torch.cat((input_b1, output_l2_up), 1))\n",
    "\n",
    "        return output_l1, output_l2, output_l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n",
    "    return gauss / gauss.sum()\n",
    "\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel, size_average=True):\n",
    "    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\n",
    "    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01 ** 2\n",
    "    C2 = 0.03 ** 2\n",
    "\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "\n",
    "class SSIM(torch.nn.Module):\n",
    "    def __init__(self, window_size=11, size_average=True):\n",
    "        super(SSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.channel = 1\n",
    "        self.window = create_window(window_size, self.channel)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        (_, channel, _, _) = img1.size()\n",
    "\n",
    "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window(self.window_size, channel)\n",
    "\n",
    "            if img1.is_cuda:\n",
    "                window = window.cuda(img1.get_device())\n",
    "            window = window.type_as(img1)\n",
    "\n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    "\n",
    "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
    "\n",
    "\n",
    "def ssim(img1, img2, window_size=11, size_average=True):\n",
    "    (_, channel, _, _) = img1.size()\n",
    "    window = create_window(window_size, channel)\n",
    "\n",
    "    if img1.is_cuda:\n",
    "        window = window.cuda(img1.get_device())\n",
    "    window = window.type_as(img1)\n",
    "\n",
    "    return _ssim(img1, img2, window, window_size, channel, size_average)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tensor_to_rgb(img_input):\n",
    "    output = img_input.cpu()\n",
    "    output = output.data.squeeze(0)\n",
    "\n",
    "    output = output.numpy()\n",
    "    output *= 255.0\n",
    "    output = output.clip(0, 255)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def compute_psnr(img1, img2):\n",
    "    mse = ((img1 - img2) ** 2).mean()\n",
    "    psnr = 10 * log10(255 * 255 / (mse + 10 ** (-10)))\n",
    "    return psnr\n",
    "\n",
    "\n",
    "class SaveData():\n",
    "    def __init__(self, save_dir, exp_name, finetuning):\n",
    "        self.save_dir = os.path.join(save_dir, exp_name)\n",
    "\n",
    "        if not finetuning:\n",
    "            if os.path.exists(self.save_dir):\n",
    "                os.system('rm -rf ' + self.save_dir)\n",
    "            os.makedirs(self.save_dir)\n",
    "        else:\n",
    "            if not os.path.exists(self.save_dir):\n",
    "                os.makedirs(self.save_dir)\n",
    "\n",
    "        self.save_dir_model = os.path.join(self.save_dir, 'model')\n",
    "        if not os.path.exists(self.save_dir_model):\n",
    "            os.makedirs(self.save_dir_model)\n",
    "\n",
    "        self.logFile = open(self.save_dir + '/log.txt', 'a')\n",
    "\n",
    "        save_dir_tensorboard = os.path.join(self.save_dir, 'logs')\n",
    "        if not os.path.exists(save_dir_tensorboard):\n",
    "            os.makedirs(save_dir_tensorboard)\n",
    "        self.writer = SummaryWriter(save_dir_tensorboard)\n",
    "\n",
    "\n",
    "    def save_params(self, args):\n",
    "        with open(self.save_dir + '/params.txt', 'w') as params_file:\n",
    "            params_file.write(str(args.__dict__) + \"\\n\\n\")\n",
    "\n",
    "\n",
    "    def save_model(self, model, epoch):\n",
    "        torch.save(model.state_dict(), self.save_dir_model + '/model_lastest.pt')\n",
    "        torch.save(model.state_dict(), self.save_dir_model + '/model_' + str(epoch) + '.pt')\n",
    "        torch.save(model, self.save_dir_model + '/model_obj.pt')\n",
    "        torch.save(epoch, self.save_dir_model + '/last_epoch.pt')\n",
    "\n",
    "    def save_log(self, log):\n",
    "        sys.stdout.flush()\n",
    "        self.logFile.write(log + '\\n')\n",
    "        self.logFile.flush()\n",
    "\n",
    "    def load_model(self, model):\n",
    "        model.load_state_dict(torch.load(self.save_dir_model + '/model_lastest.pt'))\n",
    "        last_epoch = torch.load(self.save_dir_model + '/last_epoch.pt')\n",
    "        print(\"Load mode_status from {}/model_lastest.pt, epoch: {}\".format(self.save_dir_model, last_epoch))\n",
    "        return model, last_epoch\n",
    "\n",
    "    def add_scalar(self, tag, value, step):\n",
    "        self.writer.add_scalar(tag, value, step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def augment(img_input, img_target):\n",
    "    degree = random.choice([0, 90, 180, 270])\n",
    "    img_input = transforms.functional.rotate(img_input, degree)\n",
    "    img_target = transforms.functional.rotate(img_target, degree)\n",
    "\n",
    "    # color augmentation\n",
    "    img_input = transforms.functional.adjust_gamma(img_input, 1)\n",
    "    img_target = transforms.functional.adjust_gamma(img_target, 1)\n",
    "    sat_factor = 1 + (0.2 - 0.4 * np.random.rand())\n",
    "    img_input = transforms.functional.adjust_saturation(img_input, sat_factor)\n",
    "    img_target = transforms.functional.adjust_saturation(img_target, sat_factor)\n",
    "\n",
    "    return img_input, img_target\n",
    "\n",
    "\n",
    "def getPatch(img_input, img_target, path_size):\n",
    "    w, h = img_input.size\n",
    "    p = path_size\n",
    "    x = random.randrange(0, w - p + 1)\n",
    "    y = random.randrange(0, h - p + 1)\n",
    "    img_input = img_input.crop((x, y, x + p, y + p))\n",
    "    img_target = img_target.crop((x, y, x + p, y + p))\n",
    "    return img_input, img_target\n",
    "\n",
    "\n",
    "class Gopro(data.Dataset):\n",
    "    def __init__(self, data_dir, patch_size=256, is_train=False, multi=True):\n",
    "        super(Gopro, self).__init__()\n",
    "        self.is_train = is_train\n",
    "        self.patch_size = patch_size\n",
    "        self.multi = multi\n",
    "\n",
    "        self.sharp_file_paths = []\n",
    "\n",
    "        sub_folders = os.listdir(data_dir)\n",
    "\n",
    "        for folder_name in sub_folders:\n",
    "            sharp_sub_folder = os.path.join(data_dir, folder_name, 'sharp')\n",
    "            sharp_file_names = os.listdir(sharp_sub_folder)\n",
    "\n",
    "            for file_name in sharp_file_names:\n",
    "                sharp_file_path = os.path.join(sharp_sub_folder, file_name)\n",
    "                self.sharp_file_paths.append(sharp_file_path)\n",
    "\n",
    "        self.n_samples = len(self.sharp_file_paths)\n",
    "\n",
    "    def get_img_pair(self, idx):\n",
    "        sharp_file_path = self.sharp_file_paths[idx]\n",
    "        blur_file_path = sharp_file_path.replace(\"sharp\", \"blur\")\n",
    "\n",
    "        img_input = Image.open(blur_file_path).convert('RGB')\n",
    "        img_target = Image.open(sharp_file_path).convert('RGB')\n",
    "\n",
    "        return img_input, img_target\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_input, img_target = self.get_img_pair(idx)\n",
    "\n",
    "        if self.is_train:\n",
    "            img_input, img_target = getPatch(img_input, img_target, self.patch_size)\n",
    "            img_input, img_target = augment(img_input, img_target)\n",
    "\n",
    "        input_b1 = transforms.ToTensor()(img_input)\n",
    "        target_s1 = transforms.ToTensor()(img_target)\n",
    "\n",
    "        H = input_b1.size()[1]\n",
    "        W = input_b1.size()[2]\n",
    "\n",
    "        if self.multi:\n",
    "            input_b1 = transforms.ToPILImage()(input_b1)\n",
    "            target_s1 = transforms.ToPILImage()(target_s1)\n",
    "\n",
    "            input_b2 = transforms.ToTensor()(transforms.Resize([int(H / 2), int(W / 2)])(input_b1))\n",
    "            input_b3 = transforms.ToTensor()(transforms.Resize([int(H / 4), int(W / 4)])(input_b1))\n",
    "\n",
    "            if self.is_train:\n",
    "                target_s2 = transforms.ToTensor()(transforms.Resize([int(H / 2), int(W / 2)])(target_s1))\n",
    "                target_s3 = transforms.ToTensor()(transforms.Resize([int(H / 4), int(W / 4)])(target_s1))\n",
    "            else:\n",
    "                target_s2 = []\n",
    "                target_s3 = []\n",
    "\n",
    "            input_b1 = transforms.ToTensor()(input_b1)\n",
    "            target_s1 = transforms.ToTensor()(target_s1)\n",
    "            return {'input_b1': input_b1, 'input_b2': input_b2, 'input_b3': input_b3,\n",
    "                    'target_s1': target_s1, 'target_s2': target_s2, 'target_s3': target_s3}\n",
    "        else:\n",
    "            return {'input_b1': input_b1, 'target_s1': target_s1}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/kalyan/DataSets/GOPRO_Large/train/'\n",
    "save_dir = './result'\n",
    "patch_size = 256\n",
    "batch_size = 8\n",
    "val_data_dir = None\n",
    "n_threads = 8\n",
    "exp_name = 'Net1'\n",
    "finetuning = False\n",
    "multi = False\n",
    "skip = False\n",
    "n_resblocks = 9\n",
    "n_feats = 64\n",
    "lr = 1e-4\n",
    "epochs = 40\n",
    "lr_step_size = 600\n",
    "lr_gamma = 0.1\n",
    "period = 1\n",
    "gpu = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/zsh: /opt/miniconda3/lib/libncursesw.so.6: no version information available (required by /bin/zsh)\n"
     ]
    }
   ],
   "source": [
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "!export 'PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512'\n",
    "\n",
    "def get_dataset(data_dir, patch_size=None, batch_size=1, n_threads=8, is_train=False, multi=False):\n",
    "    dataset = Gopro(data_dir, patch_size=patch_size, is_train=is_train, multi=multi)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                             drop_last=True, shuffle=is_train, num_workers=int(n_threads))\n",
    "    return dataloader\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validation(model, dataloader, multi):\n",
    "    total_psnr = 0\n",
    "    for batch, images in tqdm(enumerate(dataloader)):\n",
    "        with torch.no_grad():\n",
    "            input_b1 = Variable(images['input_b1'].cuda())\n",
    "            target_s1 = Variable(images['target_s1'].cuda())\n",
    "\n",
    "            if multi:\n",
    "                input_b2 = Variable(images['input_b2'].cuda())\n",
    "                input_b3 = Variable(images['input_b3'].cuda())\n",
    "                output_l1, _, _ = model((input_b1, input_b2, input_b3))\n",
    "            else:\n",
    "                output_l1 = model(input_b1)\n",
    "\n",
    "        output_l1 = tensor_to_rgb(output_l1)\n",
    "        target_s1 = tensor_to_rgb(target_s1)\n",
    "\n",
    "        psnr = compute_psnr(target_s1, output_l1)\n",
    "        total_psnr += psnr\n",
    "\n",
    "    return total_psnr / (batch + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 02:37:19,997 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmpcd9j7d8c\n",
      "2023-08-15 02:37:19,999 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmpcd9j7d8c/_remote_module_non_scriptable.py\n",
      "2023-08-15 02:37:20.400176: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-15 02:37:21.457598: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-08-15 02:37:22,371 - numexpr.utils - INFO - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2023-08-15 02:37:22,372 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n",
      "2023-08-15 02:37:24,690 - wandb.jupyter - ERROR - Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261bc3c795ad4a92a3aa99a15c5d0657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016670254616716798, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kalyan/gitrepo/NeedToStartARepo/oneapi/DEblurring/wandb/run-20230815_023730-rlfo7e1u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thriftyhackers/DeBlurring/runs/rlfo7e1u' target=\"_blank\">resilient-sponge-11</a></strong> to <a href='https://wandb.ai/thriftyhackers/DeBlurring' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thriftyhackers/DeBlurring' target=\"_blank\">https://wandb.ai/thriftyhackers/DeBlurring</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thriftyhackers/DeBlurring/runs/rlfo7e1u' target=\"_blank\">https://wandb.ai/thriftyhackers/DeBlurring/runs/rlfo7e1u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started.\n",
      "* Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "262it [04:54,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:04,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:04,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 5/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 6/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 7/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 8/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:04,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 9/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 10/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 11/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:04,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 12/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 13/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 14/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 15/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 16/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 17/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 18/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:04,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 19/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 20/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 21/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 22/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 23/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 24/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 25/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 26/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 27/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 28/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 29/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:04,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 30/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:04,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 31/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 32/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 33/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 34/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 35/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 36/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 37/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 38/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 39/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "262it [05:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 40/40\n"
     ]
    }
   ],
   "source": [
    "# start a new wandb run to track this script\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"DeBlurring\")\n",
    "\n",
    "\n",
    "def train():\n",
    "    print(\"Training started.\")\n",
    "    \n",
    "    if multi:\n",
    "        my_model = MultiScaleNet(n_feats=n_feats, n_resblocks=n_resblocks, is_skip=skip)\n",
    "    else:\n",
    "        my_model = SingleScaleNet(n_feats=n_feats, n_resblocks=n_resblocks, is_skip=skip)\n",
    "    my_model = my_model.cuda()\n",
    "    loss_function = nn.MSELoss().cuda()\n",
    "    optimizer = optim.Adam(my_model.parameters(), lr=lr)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, lr_step_size, lr_gamma)\n",
    "\n",
    "    my_model , optimizer = ipex.optimize(model=my_model,optimizer=optimizer)\n",
    "    # utility for saving models, parameters, and logs\n",
    "    #save = SaveData(save_dir, exp_name, finetuning)\n",
    "    #save.save_params(locals())  # Save local variables as parameters\n",
    "    #num_params = count_parameters(my_model)\n",
    "    #save.save_log(str(num_params))\n",
    "\n",
    "    # load pre-trained model if provided\n",
    "    last_epoch = -1\n",
    "    if finetuning:\n",
    "        my_model, last_epoch = save.load_model(my_model)\n",
    "    start_epoch = last_epoch + 1\n",
    "\n",
    "    # load dataset\n",
    "    data_loader = get_dataset(data_dir, patch_size=patch_size, batch_size=batch_size,\n",
    "                              n_threads=n_threads, is_train=True, multi=multi)\n",
    "    if val_data_dir:\n",
    "        valid_data_loader = get_dataset(val_data_dir, n_threads=n_threads, multi=multi)\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        print(\"* Epoch {}/{}\".format(epoch + 1, epochs))\n",
    "\n",
    "        scheduler.step()\n",
    "        learning_rate = optimizer.param_groups[0]['lr']\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch, images in tqdm(enumerate(data_loader)):\n",
    "            input_b1 = Variable(images['input_b1'].cuda())\n",
    "            target_s1 = Variable(images['target_s1'].cuda())\n",
    "\n",
    "            if multi:\n",
    "                input_b2 = Variable(images['input_b2'].cuda())\n",
    "                target_s2 = Variable(images['target_s2'].cuda())\n",
    "                input_b3 = Variable(images['input_b3'].cuda())\n",
    "                target_s3 = Variable(images['target_s3'].cuda())\n",
    "                output_l1, output_l2, output_l3 = my_model((input_b1, input_b2, input_b3))\n",
    "                loss = (loss_function(output_l1, target_s1)\n",
    "                        + loss_function(output_l2, target_s2)\n",
    "                        + loss_function(output_l3, target_s3)) / 3\n",
    "            else:\n",
    "                output_l1 = my_model(input_b1)\n",
    "                loss = loss_function(output_l1, target_s1)\n",
    "\n",
    "            my_model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.data.cpu().numpy()\n",
    "\n",
    "        loss = total_loss / (batch + 1)\n",
    "        wandb.log({\"train_loss\": loss, \"epoch\": epoch})\n",
    "\n",
    "\n",
    "        if epoch % period == 0:\n",
    "            if val_data_dir:\n",
    "                my_model.eval()\n",
    "                psnr = validation(my_model, valid_data_loader, multi)\n",
    "                my_model.train()\n",
    "\n",
    "                log = \"Epoch {}/{} \\t Learning rate: {:.5f} \\t Train total_loss: {:.5f} \\t * Val PSNR: {:.2f}\\n\".format(\n",
    "                    epoch + 1, epochs, learning_rate, loss, psnr)\n",
    "                print(log)\n",
    "                save.save_log(log)\n",
    "                wandb.log({'valid/psnr': psnr, \"epoch\": epoch})\n",
    "                \n",
    "        else:\n",
    "            log = \"Epoch {}/{} \\t Learning rate: {:.5f} \\t Train total_loss: {:.5f}\\n\".format(\n",
    "                epoch + 1, epochs, learning_rate, loss)\n",
    "            print(log)\n",
    "            save.save_log(log)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
